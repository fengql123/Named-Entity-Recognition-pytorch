{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed00e960",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchtext.vocab import build_vocab_from_iterator, GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ff4e42",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f490c35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache\\glove.42B.300d.zip:   7%|██▊                                         | 122M/1.88G [00:24<05:56, 4.92MB/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 25>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m vocab\u001b[38;5;241m.\u001b[39mset_default_index(vocab[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<unk>\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     24\u001b[0m labels_dict \u001b[38;5;241m=\u001b[39m build_vocab_from_iterator(iterator(train_labels), specials\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<pad>\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m---> 25\u001b[0m glove_vocab \u001b[38;5;241m=\u001b[39m \u001b[43mGloVe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m42B\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(vocab, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./vocabs/vocab_obj.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     27\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(labels_dict, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./vocabs/labels_dict.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch\\lib\\site-packages\\torchtext\\vocab\\vectors.py:220\u001b[0m, in \u001b[0;36mGloVe.__init__\u001b[1;34m(self, name, dim, **kwargs)\u001b[0m\n\u001b[0;32m    218\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl[name]\n\u001b[0;32m    219\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglove.\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124md.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name, \u001b[38;5;28mstr\u001b[39m(dim))\n\u001b[1;32m--> 220\u001b[0m \u001b[38;5;28msuper\u001b[39m(GloVe, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(name, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch\\lib\\site-packages\\torchtext\\vocab\\vectors.py:59\u001b[0m, in \u001b[0;36mVectors.__init__\u001b[1;34m(self, name, cache, url, unk_init, max_vectors)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munk_init \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor\u001b[38;5;241m.\u001b[39mzero_ \u001b[38;5;28;01mif\u001b[39;00m unk_init \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m unk_init\n\u001b[1;32m---> 59\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_vectors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_vectors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch\\lib\\site-packages\\torchtext\\vocab\\vectors.py:98\u001b[0m, in \u001b[0;36mVectors.cache\u001b[1;34m(self, name, cache, url, max_vectors)\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# remove the partial zip file\u001b[39;00m\n\u001b[0;32m     97\u001b[0m             os\u001b[38;5;241m.\u001b[39mremove(dest)\n\u001b[1;32m---> 98\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m     99\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting vectors into \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(cache))\n\u001b[0;32m    100\u001b[0m ext \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(dest)[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch\\lib\\site-packages\\torchtext\\vocab\\vectors.py:95\u001b[0m, in \u001b[0;36mVectors.cache\u001b[1;34m(self, name, cache, url, max_vectors)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m, unit_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, miniters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, desc\u001b[38;5;241m=\u001b[39mdest) \u001b[38;5;28;01mas\u001b[39;00m t:\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 95\u001b[0m         \u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreporthook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreporthook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# remove the partial zip file\u001b[39;00m\n\u001b[0;32m     97\u001b[0m         os\u001b[38;5;241m.\u001b[39mremove(dest)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch\\lib\\urllib\\request.py:270\u001b[0m, in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    267\u001b[0m     reporthook(blocknum, bs, size)\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 270\u001b[0m     block \u001b[38;5;241m=\u001b[39m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m block:\n\u001b[0;32m    272\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch\\lib\\http\\client.py:465\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[0;32m    464\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[1;32m--> 465\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch\\lib\\socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch\\lib\\ssl.py:1273\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1270\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1271\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1272\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1273\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1274\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch\\lib\\ssl.py:1129\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1129\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1131\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"./data/ner_datasetreference.csv\", encoding='latin1')\n",
    "\n",
    "\n",
    "def getData(data):\n",
    "    data = data.fillna(method = 'ffill')\n",
    "    data = data.drop(['POS'], axis = 1)\n",
    "    agg_function = lambda s: [(w,t) for w,t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                        s[\"Tag\"].values.tolist())]\n",
    "    group = data.groupby('Sentence #').apply(agg_function)\n",
    "    sentence = [s for s in group]\n",
    "    return [[word[0] for word in s] for s in sentence], [[lab[1] for lab in s] for s in sentence]\n",
    "\n",
    "sentences, labels = getData(data)\n",
    "split_idx = int(0.9 * len(sentences))\n",
    "train, train_labels, test, test_labels = sentences[:split_idx], labels[:split_idx], sentences[split_idx:], labels[split_idx:]\n",
    "\n",
    "\n",
    "def iterator(ss):\n",
    "    for s in ss:\n",
    "        yield s\n",
    "\n",
    "vocab = build_vocab_from_iterator(iterator(train), specials=[\"<unk>\", \"<pad>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "labels_dict = build_vocab_from_iterator(iterator(train_labels), specials=[\"<pad>\"])\n",
    "glove_vocab = GloVe(name='42B', dim=300)\n",
    "torch.save(vocab, './vocabs/vocab_obj.pth')\n",
    "torch.save(labels_dict, './vocabs/labels_dict.pth')\n",
    "torch.save(glove_vocab, './vocabs/glove_vocab.pth')\n",
    "use_glove = False\n",
    "\n",
    "\n",
    "# map-style\n",
    "class Data(Dataset):\n",
    "    def __init__(self, d, l, m_len, use_glove=False):\n",
    "        self.x_train = []\n",
    "        self.y_train = []\n",
    "        self.pad_idx = []\n",
    "        self.l = l\n",
    "        for i in range(len(d)):\n",
    "            padding = [\"<pad>\"] * (m_len - len(vocab(d[i])))\n",
    "            self.pad_idx.append(len(vocab(d[i])))\n",
    "            new_x = d[i] + padding\n",
    "            if use_glove:\n",
    "                self.x_train.append(glove_vocab.get_vecs_by_tokens(new_x))\n",
    "            else:\n",
    "                self.x_train.append(vocab(new_x))\n",
    "            if l:\n",
    "                new_y = l[i] + padding\n",
    "                self.y_train.append(labels_dict(new_y))\n",
    "            else:\n",
    "                pass\n",
    "        if use_glove:\n",
    "            self.x_train = torch.stack(self.x_train)\n",
    "        else:\n",
    "            self.x_train = torch.tensor(self.x_train)\n",
    "        if l:\n",
    "            self.y_train = torch.tensor(self.y_train)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y_train)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.l:\n",
    "            return self.x_train[idx], self.y_train[idx], self.pad_idx[idx]\n",
    "        else:\n",
    "            return self.x_train[idx], self.pad_idx[idx]\n",
    "\n",
    "max_len = max([len(s) for s in sentences])\n",
    "\n",
    "train_pipeline = Data(train, train_labels, max_len, use_glove=use_glove)\n",
    "test_pipeline = Data(test, test_labels, max_len, use_glove=use_glove)\n",
    "\n",
    "train_loader = DataLoader(train_pipeline, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f21eda4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n"
     ]
    }
   ],
   "source": [
    "print(max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a1ce58",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "077ebd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "tag_size = len(labels_dict)\n",
    "embed_size = 300\n",
    "num_layers = 5\n",
    "hidden_size = 64\n",
    "n_epochs = 20\n",
    "learning_rate = 1e-3\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f8cb45",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a1c629e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NER(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_size, num_layers, num_classes, fc_dropout=0.3, embed_dropout=0.5, use_glove=False):\n",
    "        super(NER, self).__init__()\n",
    "        self.use_glove = use_glove\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_size, num_layers=num_layers, dropout=0.2, bidirectional=True, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
    "        self.classifier = nn.Softmax(dim=2)\n",
    "        self.embed_dropout = nn.Dropout(embed_dropout)\n",
    "        self.fc_dropout = nn.Dropout(fc_dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not self.use_glove:\n",
    "            x = self.embed_dropout(self.embed(x))\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.fc_dropout(self.fc(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca4ee95",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32cabe69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss of epoch 1 is 0.69603\n",
      "test acc after epoch 1 is 0.88480\n",
      "training loss of epoch 2 is 0.59994\n",
      "test acc after epoch 2 is 0.90695\n",
      "training loss of epoch 3 is 0.58486\n",
      "test acc after epoch 3 is 0.94190\n",
      "training loss of epoch 4 is 0.57192\n",
      "test acc after epoch 4 is 0.95497\n",
      "training loss of epoch 5 is 0.56491\n",
      "test acc after epoch 5 is 0.95944\n",
      "training loss of epoch 6 is 0.56110\n",
      "test acc after epoch 6 is 0.96179\n",
      "training loss of epoch 7 is 0.55819\n",
      "test acc after epoch 7 is 0.96340\n",
      "training loss of epoch 8 is 0.55636\n",
      "test acc after epoch 8 is 0.96483\n",
      "training loss of epoch 9 is 0.55445\n",
      "test acc after epoch 9 is 0.96433\n",
      "training loss of epoch 10 is 0.55299\n",
      "test acc after epoch 10 is 0.96564\n",
      "training loss of epoch 11 is 0.55132\n",
      "test acc after epoch 11 is 0.96591\n",
      "training loss of epoch 12 is 0.55060\n",
      "test acc after epoch 12 is 0.96594\n",
      "training loss of epoch 13 is 0.54960\n",
      "test acc after epoch 13 is 0.96763\n",
      "training loss of epoch 14 is 0.54884\n",
      "test acc after epoch 14 is 0.96730\n",
      "training loss of epoch 15 is 0.54810\n",
      "test acc after epoch 15 is 0.96754\n",
      "training loss of epoch 16 is 0.54779\n",
      "test acc after epoch 16 is 0.96753\n",
      "training loss of epoch 17 is 0.54734\n",
      "test acc after epoch 17 is 0.96835\n",
      "training loss of epoch 18 is 0.54630\n",
      "test acc after epoch 18 is 0.96802\n",
      "training loss of epoch 19 is 0.54591\n",
      "test acc after epoch 19 is 0.96782\n",
      "training loss of epoch 20 is 0.54569\n",
      "test acc after epoch 20 is 0.96814\n"
     ]
    }
   ],
   "source": [
    "model = NER(vocab_size, embed_size, hidden_size, num_layers, tag_size, use_glove=use_glove).to(device=device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "def train_and_eval(model, train, test, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    acc = 0\n",
    "    count = 0\n",
    "    \n",
    "    model.train()\n",
    "    for x, y, pad_idx in train:\n",
    "        x = x.to(device=device)\n",
    "        y = y.to(device=device)\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(x)\n",
    "        predictions = predictions.view(-1, predictions.shape[-1])\n",
    "        y = y.view(-1)\n",
    "        loss = criterion(predictions, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    print(f'training loss of epoch {epoch + 1} is {(epoch_loss / len(train)):.5f}')\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for x, y, pad_idx in test:\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device).float().squeeze(1)\n",
    "            pad_idx = pad_idx[0]\n",
    "            count += pad_idx\n",
    "            predictions = torch.argmax(model(x), 2)\n",
    "            correct = torch.sum((predictions[0, :pad_idx] == y[0, :pad_idx]))\n",
    "            acc += correct\n",
    "    print(f'test acc after epoch {epoch + 1} is {(acc / count):.5f}')\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_and_eval(model, train_loader, test_loader, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089cbd5f",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4bf60b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-per', 'O', 'B-per', 'O', 'O', 'B-gpe', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "def test_model(model, sentence, use_glove):\n",
    "    with torch.inference_mode():\n",
    "        temp = Data([sentence.split()], None, max_len, use_glove)\n",
    "        for x, pad_idx in temp:\n",
    "            x = x.to(device=device)\n",
    "            if use_glove:\n",
    "                x = x.reshape((1, x.shape[0], x.shape[1]))\n",
    "            else:\n",
    "                x = x.reshape((1, -1))\n",
    "            predictions = torch.argmax(model(x), 2).squeeze().tolist()\n",
    "        return labels_dict.lookup_tokens(predictions)[:pad_idx]\n",
    "\n",
    "\n",
    "print(test_model(model, \"Alex and Alice expected the Tibetan leader to return\", use_glove))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bca841",
   "metadata": {},
   "source": [
    "### Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8a59312",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '.\\saved_no_glove.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
