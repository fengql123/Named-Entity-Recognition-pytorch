{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed00e960",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchtext.vocab import build_vocab_from_iterator, GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ff4e42",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f490c35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/ner_datasetreference.csv\", encoding='latin1')\n",
    "\n",
    "\n",
    "def getData(data):\n",
    "    data = data.fillna(method = 'ffill')\n",
    "    data = data.drop(['POS'], axis = 1)\n",
    "    agg_function = lambda s: [(w,t) for w,t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                        s[\"Tag\"].values.tolist())]\n",
    "    group = data.groupby('Sentence #').apply(agg_function)\n",
    "    sentence = [s for s in group]\n",
    "    return [[word[0] for word in s] for s in sentence], [[lab[1] for lab in s] for s in sentence]\n",
    "\n",
    "sentences, labels = getData(data)\n",
    "split_idx = int(0.9 * len(sentences))\n",
    "train, train_labels, test, test_labels = sentences[:split_idx], labels[:split_idx], sentences[split_idx:], labels[split_idx:]\n",
    "\n",
    "\n",
    "def iterator(ss):\n",
    "    for s in ss:\n",
    "        yield s\n",
    "\n",
    "vocab = build_vocab_from_iterator(iterator(train), specials=[\"<unk>\", \"<pad>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "labels_dict = build_vocab_from_iterator(iterator(train_labels), specials=[\"<pad>\"])\n",
    "glove_vocab = GloVe(name='42B', dim=300)\n",
    "torch.save(vocab, './vocabs/vocab_obj.pth')\n",
    "torch.save(labels_dict, './vocabs/labels_dict.pth')\n",
    "torch.save(glove_vocab, './vocabs/glove_vocab.pth')\n",
    "use_glove = False\n",
    "\n",
    "\n",
    "# map-style\n",
    "class Data(Dataset):\n",
    "    def __init__(self, d, l, m_len, use_glove=False):\n",
    "        self.x_train = []\n",
    "        self.y_train = []\n",
    "        self.pad_idx = []\n",
    "        self.l = l\n",
    "        for i in range(len(d)):\n",
    "            padding = [\"<pad>\"] * (m_len - len(vocab(d[i])))\n",
    "            self.pad_idx.append(len(vocab(d[i])))\n",
    "            new_x = d[i] + padding\n",
    "            if use_glove:\n",
    "                self.x_train.append(glove_vocab.get_vecs_by_tokens(new_x))\n",
    "            else:\n",
    "                self.x_train.append(vocab(new_x))\n",
    "            if l:\n",
    "                new_y = l[i] + padding\n",
    "                self.y_train.append(labels_dict(new_y))\n",
    "            else:\n",
    "                pass\n",
    "        if use_glove:\n",
    "            self.x_train = torch.stack(self.x_train)\n",
    "        else:\n",
    "            self.x_train = torch.tensor(self.x_train)\n",
    "        if l:\n",
    "            self.y_train = torch.tensor(self.y_train)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y_train)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.l:\n",
    "            return self.x_train[idx], self.y_train[idx], self.pad_idx[idx]\n",
    "        else:\n",
    "            return self.x_train[idx], self.pad_idx[idx]\n",
    "\n",
    "max_len = max([len(s) for s in sentences])\n",
    "\n",
    "train_pipeline = Data(train, train_labels, max_len, use_glove=use_glove)\n",
    "test_pipeline = Data(test, test_labels, max_len, use_glove=use_glove)\n",
    "\n",
    "train_loader = DataLoader(train_pipeline, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f21eda4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n"
     ]
    }
   ],
   "source": [
    "print(max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a1ce58",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "077ebd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "tag_size = len(labels_dict)\n",
    "embed_size = 300\n",
    "num_layers = 5\n",
    "hidden_size = 64\n",
    "n_epochs = 20\n",
    "learning_rate = 1e-3\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f8cb45",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a1c629e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NER(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_size, num_layers, num_classes, fc_dropout=0.3, embed_dropout=0.5, use_glove=False):\n",
    "        super(NER, self).__init__()\n",
    "        self.use_glove = use_glove\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_size, num_layers=num_layers, dropout=0.2, bidirectional=True, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
    "        self.classifier = nn.Softmax(dim=2)\n",
    "        self.embed_dropout = nn.Dropout(embed_dropout)\n",
    "        self.fc_dropout = nn.Dropout(fc_dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not self.use_glove:\n",
    "            x = self.embed_dropout(self.embed(x))\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.fc_dropout(self.fc(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca4ee95",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32cabe69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss of epoch 1 is 0.69603\n",
      "test acc after epoch 1 is 0.88480\n",
      "training loss of epoch 2 is 0.59994\n",
      "test acc after epoch 2 is 0.90695\n",
      "training loss of epoch 3 is 0.58486\n",
      "test acc after epoch 3 is 0.94190\n",
      "training loss of epoch 4 is 0.57192\n",
      "test acc after epoch 4 is 0.95497\n",
      "training loss of epoch 5 is 0.56491\n",
      "test acc after epoch 5 is 0.95944\n",
      "training loss of epoch 6 is 0.56110\n",
      "test acc after epoch 6 is 0.96179\n",
      "training loss of epoch 7 is 0.55819\n",
      "test acc after epoch 7 is 0.96340\n",
      "training loss of epoch 8 is 0.55636\n",
      "test acc after epoch 8 is 0.96483\n",
      "training loss of epoch 9 is 0.55445\n",
      "test acc after epoch 9 is 0.96433\n",
      "training loss of epoch 10 is 0.55299\n",
      "test acc after epoch 10 is 0.96564\n",
      "training loss of epoch 11 is 0.55132\n",
      "test acc after epoch 11 is 0.96591\n",
      "training loss of epoch 12 is 0.55060\n",
      "test acc after epoch 12 is 0.96594\n",
      "training loss of epoch 13 is 0.54960\n",
      "test acc after epoch 13 is 0.96763\n",
      "training loss of epoch 14 is 0.54884\n",
      "test acc after epoch 14 is 0.96730\n",
      "training loss of epoch 15 is 0.54810\n",
      "test acc after epoch 15 is 0.96754\n",
      "training loss of epoch 16 is 0.54779\n",
      "test acc after epoch 16 is 0.96753\n",
      "training loss of epoch 17 is 0.54734\n",
      "test acc after epoch 17 is 0.96835\n",
      "training loss of epoch 18 is 0.54630\n",
      "test acc after epoch 18 is 0.96802\n",
      "training loss of epoch 19 is 0.54591\n",
      "test acc after epoch 19 is 0.96782\n",
      "training loss of epoch 20 is 0.54569\n",
      "test acc after epoch 20 is 0.96814\n"
     ]
    }
   ],
   "source": [
    "model = NER(vocab_size, embed_size, hidden_size, num_layers, tag_size, use_glove=use_glove).to(device=device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "def train_and_eval(model, train, test, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    acc = 0\n",
    "    count = 0\n",
    "    \n",
    "    model.train()\n",
    "    for x, y, pad_idx in train:\n",
    "        x = x.to(device=device)\n",
    "        y = y.to(device=device)\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(x)\n",
    "        predictions = predictions.view(-1, predictions.shape[-1])\n",
    "        y = y.view(-1)\n",
    "        loss = criterion(predictions, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    print(f'training loss of epoch {epoch + 1} is {(epoch_loss / len(train)):.5f}')\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for x, y, pad_idx in test:\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device).float().squeeze(1)\n",
    "            pad_idx = pad_idx[0]\n",
    "            count += pad_idx\n",
    "            predictions = torch.argmax(model(x), 2)\n",
    "            correct = torch.sum((predictions[0, :pad_idx] == y[0, :pad_idx]))\n",
    "            acc += correct\n",
    "    print(f'test acc after epoch {epoch + 1} is {(acc / count):.5f}')\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_and_eval(model, train_loader, test_loader, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089cbd5f",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4bf60b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-per', 'O', 'B-per', 'O', 'O', 'B-gpe', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "def test_model(model, sentence, use_glove):\n",
    "    with torch.inference_mode():\n",
    "        temp = Data([sentence.split()], None, max_len, use_glove)\n",
    "        for x, pad_idx in temp:\n",
    "            x = x.to(device=device)\n",
    "            if use_glove:\n",
    "                x = x.reshape((1, x.shape[0], x.shape[1]))\n",
    "            else:\n",
    "                x = x.reshape((1, -1))\n",
    "            predictions = torch.argmax(model(x), 2).squeeze().tolist()\n",
    "        return labels_dict.lookup_tokens(predictions)[:pad_idx]\n",
    "\n",
    "\n",
    "print(test_model(model, \"Alex and Alice expected the Tibetan leader to return\", use_glove))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bca841",
   "metadata": {},
   "source": [
    "### Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8a59312",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '.\\saved_no_glove.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
